{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import datasets as tfd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "   if epoch < 10:\n",
    "     return lr\n",
    "   else:\n",
    "     return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tfd.cifar100.load_data(label_mode=\"coarse\")\n",
    "(x_train, y_train), (x_test, y_test) = train_data, test_data\n",
    "x_train, x_test = np.mean(x_train, axis=3), np.mean(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 20\n",
    "INPUT_SIZE = (32, 32, 1)\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "CALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3), tf.keras.callbacks.LearningRateScheduler(scheduler)] # Correct?\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set shape to (num_samples, h, w, numchannels) = (40000, 32, 32, 1)\n",
    "x_train = np.expand_dims(x_train, axis=-1) \n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Convert labels to one-of-K (one-hot) encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=N_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=N_CLASSES)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "TRAIN_SIZE, _ , _ , _ = x_train.shape\n",
    "input_img = tf.keras.Input(shape=INPUT_SIZE)\n",
    "y_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1():\n",
    "    fig, axs = plt.subplots(4, 5)\n",
    "    axs = axs.flatten()\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.imshow(x_train[i], cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "# task1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def M5(l1_value, l2_value, dropout_rate):\n",
    "    global y_pred\n",
    "    # Double number of filters on each iteration - generic first layers, specific later layers \n",
    "    reg = tf.keras.regularizers.L1L2(l1=l1_value, l2=l2_value)\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), kernel_regularizer=reg)(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2, 2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', kernel_regularizer=reg)(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2, 2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', kernel_regularizer=reg)(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2, 2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=reg)(fh1)\n",
    "    fh2 = tf.keras.layers.Dropout(dropout_rate)(fh2)\n",
    "\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=reg)(fh2)\n",
    "    fh3 = tf.keras.layers.Dropout(dropout_rate)(fh3)\n",
    "    \n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "M5(0, 0, 0)\n",
    "model_name = 'M5-dropout'\n",
    "\n",
    "model = tf.keras.Model(input_img, y_pred)\n",
    "# model.summary()\n",
    "\n",
    "x_train_n = x_train\n",
    "x_val_n = x_val\n",
    "\n",
    "sampler = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                                                          width_shift_range=0.1, height_shift_range=0.1).flow(x_train_n, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# model.compile(optimizer=optimizer, loss=LOSS, metrics=METRICS)\n",
    "# history = model.fit(sampler, epochs=EPOCHS, steps_per_epoch=TRAIN_SIZE//BATCH_SIZE, callbacks=CALLBACKS, validation_data=(x_val_n, y_val))\n",
    "# history_df = pd.DataFrame(history.history)\n",
    "# history_df.to_csv(f'{model_name}_training_history.csv', index=False)\n",
    "# test_loss, test_acc = model.evaluate(x_val_n, y_val)\n",
    "# evaluation_df = pd.DataFrame({'Test Loss': [test_loss], 'Test Accuracy': [test_acc]})\n",
    "# evaluation_df.to_csv(f'{model_name}_evaluation_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam-model-env",
   "language": "python",
   "name": "sam-model-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
