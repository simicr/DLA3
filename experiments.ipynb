{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import datasets as tfd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "   if epoch < 10:\n",
    "     return lr\n",
    "   else:\n",
    "     return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tfd.cifar100.load_data(label_mode=\"coarse\")\n",
    "(x_train, y_train), (x_test, y_test) = train_data, test_data\n",
    "x_train, x_test = np.mean(x_train, axis=3), np.mean(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 20\n",
    "INPUT_SIZE = (32, 32, 1)\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "CALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3), tf.keras.callbacks.LearningRateScheduler(scheduler)] # Correct?\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set shape to (num_samples, h, w, numchannels) = (40000, 32, 32, 1)\n",
    "x_train = np.expand_dims(x_train, axis=-1) \n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Convert labels to one-of-K (one-hot) encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=N_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=N_CLASSES)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "TRAIN_SIZE, _ , _ , _ = x_train.shape\n",
    "input_img = tf.keras.Input(shape=INPUT_SIZE)\n",
    "y_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1():\n",
    "    fig, axs = plt.subplots(4, 5)\n",
    "    axs = axs.flatten()\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.imshow(x_train[i], cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "# task1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def M5(l1_value, l2_value):\n",
    "    global y_pred\n",
    "    # Double number of filters on each iteration - generic first layers, specific later layers \n",
    "    reg = tf.keras.regularizers.L1L2(l1=l1_value, l2=l2_value)\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), kernel_regularizer=reg)(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2, 2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', kernel_regularizer=reg)(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2, 2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', kernel_regularizer=reg)(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2, 2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=reg)(fh1)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=reg)(fh2)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPooli  (None, 15, 15, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 15, 15, 128)       36992     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 7, 7, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPooli  (None, 3, 3, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               590080    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 958036 (3.65 MB)\n",
      "Trainable params: 958036 (3.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1162/1250 [==========================>...] - ETA: 10s - loss: 8.1788 - accuracy: 0.0460"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam()\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mLOSS, metrics\u001b[38;5;241m=\u001b[39mMETRICS)\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_SIZE\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCALLBACKS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m history_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m     22\u001b[0m history_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_training_history.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\keras\\src\\engine\\training.py:1733\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1731\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1733\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1734\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m         ):\n\u001b[0;32m   1741\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1401\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1401\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1402\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1403\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1406\u001b[0m )\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:688\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    687\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    690\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:815\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 815\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:794\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    792\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 794\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    797\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    798\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    800\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    801\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    802\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:784\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    783\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 784\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:581\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    580\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    584\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "M5()\n",
    "model_name = 'M5-regularized'\n",
    "\n",
    "model = tf.keras.Model(input_img, y_pred)\n",
    "# model.summary()\n",
    "\n",
    "x_train_n = x_train\n",
    "x_val_n = x_val\n",
    "\n",
    "x_train_n = (x_train.astype('float32')) / 255\n",
    "x_val_n = (x_val.astype('float32')) / 255\n",
    "\n",
    "sampler = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                                                          width_shift_range=0.1, height_shift_range=0.1).flow(x_train_n, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=LOSS, metrics=METRICS)\n",
    "history = model.fit(sampler, epochs=EPOCHS, steps_per_epoch=TRAIN_SIZE//BATCH_SIZE, callbacks=CALLBACKS, validation_data=(x_val_n, y_val))\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(f'{model_name}_training_history.csv', index=False)\n",
    "test_loss, test_acc = model.evaluate(x_val_n, y_val)\n",
    "evaluation_df = pd.DataFrame({'Test Loss': [test_loss], 'Test Accuracy': [test_acc]})\n",
    "evaluation_df.to_csv(f'{model_name}_evaluation_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 53.2222 - accuracy: 0.0481 - val_loss: 14.4787 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 14.6505 - accuracy: 0.0481 - val_loss: 14.8288 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 66s 52ms/step - loss: 14.9009 - accuracy: 0.0483 - val_loss: 14.9804 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 14.9114 - accuracy: 0.0484 - val_loss: 14.7778 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.7778 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 66s 52ms/step - loss: 52.2854 - accuracy: 0.0474 - val_loss: 14.7202 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 14.6424 - accuracy: 0.0487 - val_loss: 14.4946 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 14.5138 - accuracy: 0.0462 - val_loss: 14.5837 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.4030 - accuracy: 0.0494 - val_loss: 14.3642 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.3440 - accuracy: 0.0471 - val_loss: 14.2601 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.2641 - accuracy: 0.0466 - val_loss: 14.1860 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 14.1754 - accuracy: 0.0472 - val_loss: 14.1414 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 14.1741 - accuracy: 0.0487 - val_loss: 14.2333 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 14.2333 - accuracy: 0.0477 - val_loss: 14.3488 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.2859 - accuracy: 0.0483 - val_loss: 14.2214 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.2214 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 52.0428 - accuracy: 0.0481 - val_loss: 14.7701 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7864 - accuracy: 0.0485 - val_loss: 14.6529 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7735 - accuracy: 0.0483 - val_loss: 14.9494 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7593 - accuracy: 0.0487 - val_loss: 14.7245 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 14.7447 - accuracy: 0.0490 - val_loss: 14.5905 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7307 - accuracy: 0.0479 - val_loss: 14.7253 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7183 - accuracy: 0.0480 - val_loss: 14.7546 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7066 - accuracy: 0.0479 - val_loss: 14.7452 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.7452 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 66s 52ms/step - loss: 52.0705 - accuracy: 0.0485 - val_loss: 14.7644 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7900 - accuracy: 0.0465 - val_loss: 14.6544 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 14.7900 - accuracy: 0.0488 - val_loss: 14.9760 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 14.7896 - accuracy: 0.0496 - val_loss: 14.7637 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7890 - accuracy: 0.0459 - val_loss: 14.6242 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7890 - accuracy: 0.0453 - val_loss: 14.7600 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7882 - accuracy: 0.0482 - val_loss: 14.8342 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7877 - accuracy: 0.0484 - val_loss: 14.8439 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.8439 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 52.1022 - accuracy: 0.0482 - val_loss: 14.7558 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7918 - accuracy: 0.0488 - val_loss: 14.6797 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 14.7916 - accuracy: 0.0483 - val_loss: 14.9967 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7910 - accuracy: 0.0474 - val_loss: 14.7666 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7904 - accuracy: 0.0496 - val_loss: 14.6221 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7900 - accuracy: 0.0474 - val_loss: 14.7574 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7892 - accuracy: 0.0477 - val_loss: 14.8327 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7885 - accuracy: 0.0481 - val_loss: 14.8503 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.8503 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 69s 54ms/step - loss: 52.1082 - accuracy: 0.0494 - val_loss: 14.7600 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 14.7909 - accuracy: 0.0490 - val_loss: 14.6761 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 14.7906 - accuracy: 0.0492 - val_loss: 15.0012 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 14.7899 - accuracy: 0.0474 - val_loss: 14.7577 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 14.7891 - accuracy: 0.0473 - val_loss: 14.6365 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 14.7889 - accuracy: 0.0478 - val_loss: 14.7645 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 14.7881 - accuracy: 0.0471 - val_loss: 14.8212 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 14.7874 - accuracy: 0.0469 - val_loss: 14.8658 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.8658 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 52.1274 - accuracy: 0.0472 - val_loss: 14.7734 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7857 - accuracy: 0.0490 - val_loss: 14.6778 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7854 - accuracy: 0.0489 - val_loss: 14.9796 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7849 - accuracy: 0.0482 - val_loss: 14.7688 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 14.7841 - accuracy: 0.0487 - val_loss: 14.6192 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 66s 52ms/step - loss: 14.7838 - accuracy: 0.0484 - val_loss: 14.7502 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 14.7831 - accuracy: 0.0477 - val_loss: 14.8269 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7823 - accuracy: 0.0485 - val_loss: 14.8556 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.8556 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 68s 53ms/step - loss: 52.1260 - accuracy: 0.0487 - val_loss: 14.7523 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7835 - accuracy: 0.0477 - val_loss: 14.6617 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 14.7833 - accuracy: 0.0487 - val_loss: 14.9710 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7828 - accuracy: 0.0487 - val_loss: 14.7487 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7821 - accuracy: 0.0485 - val_loss: 14.6132 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7819 - accuracy: 0.0481 - val_loss: 14.7468 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7811 - accuracy: 0.0468 - val_loss: 14.8169 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7805 - accuracy: 0.0482 - val_loss: 14.8365 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.8365 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 66s 52ms/step - loss: 52.1188 - accuracy: 0.0485 - val_loss: 14.7792 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7928 - accuracy: 0.0475 - val_loss: 14.6629 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7924 - accuracy: 0.0476 - val_loss: 15.0026 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7921 - accuracy: 0.0448 - val_loss: 14.7634 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7912 - accuracy: 0.0486 - val_loss: 14.6132 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7909 - accuracy: 0.0484 - val_loss: 14.7677 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7902 - accuracy: 0.0488 - val_loss: 14.8294 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 14.7895 - accuracy: 0.0473 - val_loss: 14.8520 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.8520 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 52.0751 - accuracy: 0.0485 - val_loss: 14.7730 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 14.7942 - accuracy: 0.0486 - val_loss: 14.6852 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 14.7940 - accuracy: 0.0475 - val_loss: 14.9858 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7933 - accuracy: 0.0478 - val_loss: 14.7722 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7925 - accuracy: 0.0489 - val_loss: 14.6199 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7921 - accuracy: 0.0475 - val_loss: 14.7711 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7914 - accuracy: 0.0472 - val_loss: 14.8242 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 14.7906 - accuracy: 0.0484 - val_loss: 14.8676 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 14.8676 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 9.2808 - accuracy: 0.0485 - val_loss: 4.2582 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 4.2554 - accuracy: 0.0483 - val_loss: 4.2470 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 4.2579 - accuracy: 0.0490 - val_loss: 4.2681 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 66s 52ms/step - loss: 4.2586 - accuracy: 0.0466 - val_loss: 4.2421 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 4.2586 - accuracy: 0.0479 - val_loss: 4.2729 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.2588 - accuracy: 0.0481 - val_loss: 4.2454 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.2587 - accuracy: 0.0495 - val_loss: 4.2514 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 4.2514 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 8.0182 - accuracy: 0.0487 - val_loss: 4.1384 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 4.1554 - accuracy: 0.0486 - val_loss: 4.1719 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 4.1807 - accuracy: 0.0481 - val_loss: 4.1872 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1818 - accuracy: 0.0486 - val_loss: 4.1694 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.1694 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 71s 56ms/step - loss: 7.9117 - accuracy: 0.0487 - val_loss: 4.1580 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1530 - accuracy: 0.0465 - val_loss: 4.1356 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1396 - accuracy: 0.0487 - val_loss: 4.1441 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1286 - accuracy: 0.0467 - val_loss: 4.1247 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1227 - accuracy: 0.0477 - val_loss: 4.1112 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1150 - accuracy: 0.0468 - val_loss: 4.1085 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1059 - accuracy: 0.0492 - val_loss: 4.1022 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1056 - accuracy: 0.0483 - val_loss: 4.1096 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1112 - accuracy: 0.0485 - val_loss: 4.1195 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1164 - accuracy: 0.0470 - val_loss: 4.1096 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.1096 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 71s 56ms/step - loss: 7.9045 - accuracy: 0.0485 - val_loss: 4.1680 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1689 - accuracy: 0.0476 - val_loss: 4.1548 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1678 - accuracy: 0.0465 - val_loss: 4.1825 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1665 - accuracy: 0.0480 - val_loss: 4.1618 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1651 - accuracy: 0.0467 - val_loss: 4.1492 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1638 - accuracy: 0.0496 - val_loss: 4.1629 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 4.1626 - accuracy: 0.0481 - val_loss: 4.1640 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1614 - accuracy: 0.0478 - val_loss: 4.1641 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.1641 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 71s 56ms/step - loss: 7.9066 - accuracy: 0.0468 - val_loss: 4.1660 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1695 - accuracy: 0.0469 - val_loss: 4.1556 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 4.1694 - accuracy: 0.0487 - val_loss: 4.1864 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 4.1694 - accuracy: 0.0476 - val_loss: 4.1663 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1693 - accuracy: 0.0472 - val_loss: 4.1520 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1692 - accuracy: 0.0481 - val_loss: 4.1665 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1691 - accuracy: 0.0492 - val_loss: 4.1691 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 4.1689 - accuracy: 0.0484 - val_loss: 4.1739 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.1739 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 7.9010 - accuracy: 0.0478 - val_loss: 4.1658 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 4.1681 - accuracy: 0.0495 - val_loss: 4.1537 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 4.1681 - accuracy: 0.0480 - val_loss: 4.1855 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 4.1681 - accuracy: 0.0486 - val_loss: 4.1662 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 4.1681 - accuracy: 0.0485 - val_loss: 4.1512 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 4.1681 - accuracy: 0.0493 - val_loss: 4.1675 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 68s 55ms/step - loss: 4.1681 - accuracy: 0.0487 - val_loss: 4.1678 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 71s 56ms/step - loss: 4.1681 - accuracy: 0.0472 - val_loss: 4.1728 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.1728 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 7.9034 - accuracy: 0.0491 - val_loss: 4.1662 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1687 - accuracy: 0.0476 - val_loss: 4.1548 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 66s 52ms/step - loss: 4.1687 - accuracy: 0.0485 - val_loss: 4.1851 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1687 - accuracy: 0.0469 - val_loss: 4.1658 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1686 - accuracy: 0.0466 - val_loss: 4.1499 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1686 - accuracy: 0.0491 - val_loss: 4.1663 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1685 - accuracy: 0.0474 - val_loss: 4.1684 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1685 - accuracy: 0.0472 - val_loss: 4.1731 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 4.1731 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 7.9033 - accuracy: 0.0479 - val_loss: 4.1704 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1702 - accuracy: 0.0477 - val_loss: 4.1558 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 4.1702 - accuracy: 0.0493 - val_loss: 4.1865 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1701 - accuracy: 0.0458 - val_loss: 4.1696 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1701 - accuracy: 0.0479 - val_loss: 4.1522 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 4.1700 - accuracy: 0.0481 - val_loss: 4.1672 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 4.1700 - accuracy: 0.0485 - val_loss: 4.1701 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 4.1699 - accuracy: 0.0470 - val_loss: 4.1759 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.1759 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 75s 60ms/step - loss: 7.9027 - accuracy: 0.0480 - val_loss: 4.1673 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1708 - accuracy: 0.0482 - val_loss: 4.1580 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1708 - accuracy: 0.0475 - val_loss: 4.1872 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1707 - accuracy: 0.0470 - val_loss: 4.1692 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1707 - accuracy: 0.0483 - val_loss: 4.1512 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1706 - accuracy: 0.0497 - val_loss: 4.1680 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1706 - accuracy: 0.0482 - val_loss: 4.1702 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1705 - accuracy: 0.0490 - val_loss: 4.1759 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.1759 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 75s 60ms/step - loss: 7.9039 - accuracy: 0.0494 - val_loss: 4.1675 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1687 - accuracy: 0.0474 - val_loss: 4.1546 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1688 - accuracy: 0.0467 - val_loss: 4.1854 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1687 - accuracy: 0.0478 - val_loss: 4.1673 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1686 - accuracy: 0.0493 - val_loss: 4.1494 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 73s 59ms/step - loss: 4.1686 - accuracy: 0.0471 - val_loss: 4.1661 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1685 - accuracy: 0.0476 - val_loss: 4.1698 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 4.1685 - accuracy: 0.0498 - val_loss: 4.1730 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.1730 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 75s 59ms/step - loss: 4.7165 - accuracy: 0.0478 - val_loss: 3.1052 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 3.1100 - accuracy: 0.0466 - val_loss: 3.1126 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 73s 59ms/step - loss: 3.1147 - accuracy: 0.0470 - val_loss: 3.1188 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 3.1161 - accuracy: 0.0466 - val_loss: 3.1147 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 3.1147 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 3.6348 - accuracy: 0.0484 "
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_n = (x_train.astype('float32')) / 255\n",
    "x_val_n = (x_val.astype('float32')) / 255\n",
    "\n",
    "\n",
    "for l1 in [10**(-i) for i in range(1, 11)]:\n",
    "    for l2 in [10**(-i) for i in range(1, 11)]:\n",
    "        M5(l1, l2)\n",
    "        model_name = f'M5-l1_{l1}_l2_{l2}'\n",
    "\n",
    "        \n",
    "        model = tf.keras.Model(input_img, y_pred)\n",
    "        sampler = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                                                            width_shift_range=0.1, height_shift_range=0.1).flow(x_train_n, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=LOSS, metrics=METRICS)\n",
    "        history = model.fit(sampler, epochs=EPOCHS, steps_per_epoch=TRAIN_SIZE//BATCH_SIZE, callbacks=CALLBACKS, validation_data=(x_val_n, y_val))\n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df.to_csv(f'{model_name}_training_history.csv', index=False)\n",
    "        test_loss, test_acc = model.evaluate(x_val_n, y_val)\n",
    "        evaluation_df = pd.DataFrame({'Test Loss': [test_loss], 'Test Accuracy': [test_acc]})\n",
    "        evaluation_df.to_csv(f'{model_name}_evaluation_results.csv', index=False)\n",
    "\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Validation loss history')\n",
    "        plt.ylabel('Loss value')\n",
    "        plt.xlabel('No. epoch')\n",
    "        plt.savefig(f'{model_name}_val_loss.png')  # Save with the model name\n",
    "        plt.close()  # Close the plot to avoid overlapping plots\n",
    "\n",
    "        # Plot history: Accuracy\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Validation accuracy history')\n",
    "        plt.ylabel('Accuracy value (%)')\n",
    "        plt.xlabel('No. epoch')\n",
    "        plt.savefig(f'{model_name}_val_accuracy.png')  # Save with the model name\n",
    "        plt.close()  # Close the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 84s 67ms/step - loss: 541.8098 - accuracy: 0.0485 - val_loss: 116.5973 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 79s 63ms/step - loss: 117.8778 - accuracy: 0.0495 - val_loss: 119.6285 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 91s 73ms/step - loss: 120.3782 - accuracy: 0.0470 - val_loss: 120.8063 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 91s 73ms/step - loss: 120.4950 - accuracy: 0.0470 - val_loss: 120.0048 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 120.0048 - accuracy: 0.0500\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 99s 78ms/step - loss: 519.2474 - accuracy: 0.0477 - val_loss: 118.9494 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 88s 70ms/step - loss: 118.1752 - accuracy: 0.0487 - val_loss: 116.6285 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 88s 70ms/step - loss: 116.8276 - accuracy: 0.0477 - val_loss: 116.9631 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 90s 72ms/step - loss: 115.7249 - accuracy: 0.0476 - val_loss: 115.3495 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 104s 83ms/step - loss: 115.0987 - accuracy: 0.0478 - val_loss: 114.2171 - val_accuracy: 0.0500 - lr: 0.0010\n",
      "Epoch 6/10\n",
      " 954/1250 [=====================>........] - ETA: 33s - loss: 114.4482 - accuracy: 0.0498"
     ]
    }
   ],
   "source": [
    "x_train_n = x_train\n",
    "x_val_n = x_val\n",
    "\n",
    "\n",
    "\n",
    "for l1 in [10**(-i) for i in range(0, 11)]:\n",
    "    for l2 in [10**(-i) for i in range(0, 11)]:\n",
    "        M5(l1, l2)\n",
    "        model_name = f'M5-no-norm-l1_{l1}_l2_{l2}'\n",
    "\n",
    "        \n",
    "        model = tf.keras.Model(input_img, y_pred)\n",
    "        sampler = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                                                            width_shift_range=0.1, height_shift_range=0.1).flow(x_train_n, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=LOSS, metrics=METRICS)\n",
    "        history = model.fit(sampler, epochs=EPOCHS, steps_per_epoch=TRAIN_SIZE//BATCH_SIZE, callbacks=CALLBACKS, validation_data=(x_val_n, y_val))\n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df.to_csv(f'{model_name}_training_history.csv', index=False)\n",
    "        test_loss, test_acc = model.evaluate(x_val_n, y_val)\n",
    "        evaluation_df = pd.DataFrame({'Test Loss': [test_loss], 'Test Accuracy': [test_acc]})\n",
    "        evaluation_df.to_csv(f'{model_name}_evaluation_results.csv', index=False)\n",
    "\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Validation loss history')\n",
    "        plt.ylabel('Loss value')\n",
    "        plt.xlabel('No. epoch')\n",
    "        plt.savefig(f'{model_name}_val_loss.png')  # Save with the model name\n",
    "        plt.close()  # Close the plot to avoid overlapping plots\n",
    "\n",
    "        # Plot history: Accuracy\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Validation accuracy history')\n",
    "        plt.ylabel('Accuracy value (%)')\n",
    "        plt.xlabel('No. epoch')\n",
    "        plt.savefig(f'{model_name}_val_accuracy.png')  # Save with the model name\n",
    "        plt.close()  # Close the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam-model-env",
   "language": "python",
   "name": "sam-model-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
