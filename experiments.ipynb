{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import datasets as tfd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "   if epoch < 10:\n",
    "     return lr\n",
    "   else:\n",
    "     return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tfd.cifar100.load_data(label_mode=\"coarse\")\n",
    "(x_train, y_train), (x_test, y_test) = train_data, test_data\n",
    "x_train, x_test = np.mean(x_train, axis=3), np.mean(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 20\n",
    "INPUT_SIZE = (32, 32, 1)\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "CALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True), tf.keras.callbacks.LearningRateScheduler(scheduler)]\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set shape to (num_samples, h, w, numchannels) = (40000, 32, 32, 1)\n",
    "x_train = np.expand_dims(x_train, axis=-1) \n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Convert labels to one-of-K (one-hot) encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=N_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=N_CLASSES)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "TRAIN_SIZE, _ , _ , _ = x_train.shape\n",
    "input_img = tf.keras.Input(shape=INPUT_SIZE)\n",
    "y_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = np.sum(y_train, axis=0)\n",
    "total_samples = len(y_train)\n",
    "class_proportions = class_counts / total_samples\n",
    "\n",
    "# Print the proportions for each class\n",
    "for class_label, proportion in enumerate(class_proportions):\n",
    "    print(f\"Class {class_label}: Proportion - {proportion:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dict = pickle.load(open(\"cifar20_perturb_test.pkl\", \"rb\"))\n",
    "x_perturb, y_perturb = dict['x_perturb'], dict['y_perturb']\n",
    "x_perturb = np.mean(x_perturb, axis=3)\n",
    "x_perturb = np.expand_dims(x_perturb, axis=-1)\n",
    "y_perturb = tf.keras.utils.to_categorical(y_perturb, num_classes=N_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1():\n",
    "    fig, axs = plt.subplots(4, 5)\n",
    "    axs = axs.flatten()\n",
    "    for i, ax in enumerate(axs):\n",
    "        print(x_train[i].shape)\n",
    "        ax.imshow(x_train[i], cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def task_e_exploration():\n",
    "    augmented_images = []\n",
    "    num_images_to_augment = 20  # You can change this number based on your requirements\n",
    "\n",
    "    # Applying augmentation to a subset of images\n",
    "    for i in range(num_images_to_augment):\n",
    "        augmented_img = data_augmenter.random_transform(x_train[i])\n",
    "        print(augmented_img.shape)\n",
    "        augmented_images.append(augmented_img)\n",
    "\n",
    "    # Displaying the original and augmented images\n",
    "    fig, axs = plt.subplots(4, 5)\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.imshow(augmented_images[i], cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E1():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh1)\n",
    "    fh2 = tf.keras.layers.Dropout(0.1)(fh2)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh2)\n",
    "    fh3 = tf.keras.layers.Dropout(0.1)(fh3)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#batch norm on all layers \n",
    "def E2():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.BatchNormalization()(h0)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.BatchNormalization()(h1)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.BatchNormalization()(h2)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh1)\n",
    "    fh2 = tf.keras.layers.BatchNormalization()(fh2)\n",
    "    fh2 = tf.keras.layers.Dropout(0.1)(fh2)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh2)\n",
    "    fh3 = tf.keras.layers.BatchNormalization()(fh3)\n",
    "    fh3 = tf.keras.layers.Dropout(0.1)(fh3)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "\n",
    "\n",
    "#batch norm on dense layers only\n",
    "def E3():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh1)\n",
    "    fh2 = tf.keras.layers.BatchNormalization()(fh2)\n",
    "    fh2 = tf.keras.layers.Dropout(0.1)(fh2)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh2)\n",
    "    fh3 = tf.keras.layers.BatchNormalization()(fh3)\n",
    "    fh3 = tf.keras.layers.Dropout(0.1)(fh3)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full, y_full = train_data\n",
    "x_full = np.mean(x_full, axis=3)\n",
    "x_full = np.expand_dims(x_full, axis=-1) \n",
    "y_full = tf.keras.utils.to_categorical(y_full, num_classes=N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "data_augmenter_spins = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                                                          width_shift_range=0.1, height_shift_range=0.1,\n",
    "                                                          validation_split=0.2)\n",
    "\n",
    "data_augmented_brightness = tf.keras.preprocessing.image.ImageDataGenerator(zca_whitening = True,  brightness_range= [0.5, 1], validation_split=0.2)\n",
    "\n",
    "data_augmented_mixed = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                                                          width_shift_range=0.1, height_shift_range=0.1,\n",
    "                                                          zca_whitening = True,  brightness_range= [0.5, 1],\n",
    "                                                          validation_split=0.2)\n",
    "\n",
    "sampler = tf.keras.preprocessing.image.ImageDataGenerator().flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "sampler_augmented_spins = data_augmenter_spins.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "sampler_augmented_brightness = data_augmented_brightness.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "sampler_augmented_mixed = data_augmented_mixed.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "def train_and_evaluate_model(sampler, model_name, retrain=False, perturbation=False):\n",
    "    model_save_path = f\"{model_name}_model.h5\"\n",
    "    history_csv_path = f'results/{model_name}_training_history.csv'\n",
    "    evaluation_csv_path = f'results/{model_name}_evaluation_results.csv'\n",
    "    perturbation_csv_path = f'results/{model_name}_perturbed_results.csv'\n",
    "\n",
    "    if not retrain and os.path.exists(model_save_path):\n",
    "        # Load the existing model\n",
    "        model = tf.keras.models.load_model(model_save_path)\n",
    "        print(f\"Loaded pre-trained model '{model_name}'.\")\n",
    "\n",
    "    else:\n",
    "        model = tf.keras.Model(input_img, y_pred)\n",
    "        print(model_name)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=LOSS, metrics=METRICS)\n",
    "        history = model.fit(sampler, epochs=EPOCHS, steps_per_epoch=TRAIN_SIZE // BATCH_SIZE, callbacks=CALLBACKS, validation_data=(x_val, y_val))\n",
    "        \n",
    "        model.save(model_save_path)\n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df.to_csv(history_csv_path, index=False)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_val, y_val)\n",
    "  \n",
    "\n",
    "    evaluation_df = pd.DataFrame({'Test Loss': [test_loss], 'Test Accuracy': [test_acc]})\n",
    "    evaluation_df.to_csv(evaluation_csv_path, index=False)\n",
    "\n",
    "    if perturbation:\n",
    "        perturbation_loss, perturbation_acc = model.evaluate(x_perturb, y_perturb)\n",
    "        perturbation_df = pd.DataFrame({'Perturbation Loss': [perturbation_loss], 'Perturbation Accuracy': [perturbation_acc]})\n",
    "        perturbation_df.to_csv(perturbation_csv_path, index=False)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C1():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh1)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu',  kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh2)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "# Adding L2 reg with lambda=0.1 on the FC part\n",
    "def C2():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(fh1)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu',  kernel_regularizer=tf.keras.regularizers.L2(0.1))(fh2)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "# Adding L2 reg with lambda=0.001 in the FC part\n",
    "def C3():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001))(fh1)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu',  kernel_regularizer=tf.keras.regularizers.L2(0.001))(fh2)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "# Adding dropout with rate 0.5 in the FC part.\n",
    "def C4():\n",
    "    global y_pred\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu')(fh1)\n",
    "    fh2 = tf.keras.layers.Dropout(0.5)(fh2)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu')(fh2)\n",
    "    fh3 = tf.keras.layers.Dropout(0.5)(fh3)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "# Adding dropout with rate 0.1 in the FC part.\n",
    "def C5():\n",
    "    global y_pred\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu')(fh1)\n",
    "    fh2 = tf.keras.layers.Dropout(0.1)(fh2)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu')(fh2)\n",
    "    fh3 = tf.keras.layers.Dropout(0.1)(fh3)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "\n",
    "# Addinng dropout with 0.1 and L2 reg with lambda = 0.001 \n",
    "def C6():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001))(fh1)\n",
    "    fh2 = tf.keras.layers.Dropout(0.1)(fh2)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu',  kernel_regularizer=tf.keras.regularizers.L2(0.001))(fh2)\n",
    "    fh3 = tf.keras.layers.Dropout(0.1)(fh3)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "# Addinng dropout with 0.1 and L2 reg with lambda = 0.01\n",
    "def C7():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh1)\n",
    "    fh2 = tf.keras.layers.Dropout(0.1)(fh2)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(fh2)\n",
    "    fh3 = tf.keras.layers.Dropout(0.1)(fh3)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)\n",
    "\n",
    "# Adding dropout with 0.1 with L2 reg with lambda 0.1\n",
    "def C8():\n",
    "    global y_pred\n",
    "    h0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(input_img)\n",
    "    h0 = tf.keras.layers.MaxPool2D((2,2))(h0)\n",
    "\n",
    "    h1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(h0)\n",
    "    h1 = tf.keras.layers.MaxPool2D((2,2))(h1)\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(h1)\n",
    "    h2 = tf.keras.layers.MaxPool2D((2,2))(h2)\n",
    "\n",
    "    fh1 = tf.keras.layers.Flatten()(h2)\n",
    "    fh2 = tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(fh1)\n",
    "    fh2 = tf.keras.layers.Dropout(0.1)(fh2)\n",
    "    fh3 = tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(fh2)\n",
    "    fh3 = tf.keras.layers.Dropout(0.1)(fh3)\n",
    "    y_pred = tf.keras.layers.Dense(units=N_CLASSES, activation='softmax')(fh3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1\n",
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 157s 122ms/step - loss: 4.2114 - accuracy: 0.2072 - val_loss: 2.9978 - val_accuracy: 0.2781 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 108s 87ms/step - loss: 2.6461 - accuracy: 0.3146 - val_loss: 2.4558 - val_accuracy: 0.3335 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 129s 103ms/step - loss: 2.2953 - accuracy: 0.3699 - val_loss: 2.2896 - val_accuracy: 0.3660 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 130s 104ms/step - loss: 2.1489 - accuracy: 0.4072 - val_loss: 2.1579 - val_accuracy: 0.4067 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 133s 107ms/step - loss: 2.0579 - accuracy: 0.4331 - val_loss: 2.1420 - val_accuracy: 0.4089 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 123s 99ms/step - loss: 1.9826 - accuracy: 0.4578 - val_loss: 2.1551 - val_accuracy: 0.4128 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 88s 71ms/step - loss: 1.9110 - accuracy: 0.4777 - val_loss: 2.0920 - val_accuracy: 0.4244 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 1.8535 - accuracy: 0.4927 - val_loss: 2.1298 - val_accuracy: 0.4185 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.7933 - accuracy: 0.5103 - val_loss: 2.1584 - val_accuracy: 0.4167 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 1.7343 - accuracy: 0.5332 - val_loss: 2.1573 - val_accuracy: 0.4226 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vdako\\anaconda3\\envs\\sam-model-env\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 18ms/step - loss: 2.0920 - accuracy: 0.4244\n",
      "C2\n",
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 75s 59ms/step - loss: 7.4376 - accuracy: 0.1624 - val_loss: 2.7648 - val_accuracy: 0.2387 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 73s 58ms/step - loss: 2.6489 - accuracy: 0.2545 - val_loss: 2.5109 - val_accuracy: 0.2849 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 2.4833 - accuracy: 0.3002 - val_loss: 2.4615 - val_accuracy: 0.3169 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 92s 73ms/step - loss: 2.3761 - accuracy: 0.3345 - val_loss: 2.3466 - val_accuracy: 0.3395 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 2.2814 - accuracy: 0.3595 - val_loss: 2.2727 - val_accuracy: 0.3661 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 113s 91ms/step - loss: 2.1993 - accuracy: 0.3839 - val_loss: 2.2193 - val_accuracy: 0.3716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 2.1300 - accuracy: 0.3998 - val_loss: 2.2369 - val_accuracy: 0.3699 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 2.0766 - accuracy: 0.4218 - val_loss: 2.1825 - val_accuracy: 0.3915 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 2.0183 - accuracy: 0.4351 - val_loss: 2.1937 - val_accuracy: 0.3942 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 112s 89ms/step - loss: 1.9732 - accuracy: 0.4486 - val_loss: 2.1622 - val_accuracy: 0.3996 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 1.8942 - accuracy: 0.4703 - val_loss: 2.1329 - val_accuracy: 0.4095 - lr: 9.0484e-04\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 116s 93ms/step - loss: 1.8032 - accuracy: 0.4953 - val_loss: 2.0948 - val_accuracy: 0.4178 - lr: 8.1873e-04\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 112s 89ms/step - loss: 1.7312 - accuracy: 0.5157 - val_loss: 2.0822 - val_accuracy: 0.4205 - lr: 7.4082e-04\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 1.6574 - accuracy: 0.5368 - val_loss: 2.0722 - val_accuracy: 0.4343 - lr: 6.7032e-04\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 99s 79ms/step - loss: 1.5816 - accuracy: 0.5567 - val_loss: 2.0631 - val_accuracy: 0.4417 - lr: 6.0653e-04\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 88s 70ms/step - loss: 1.5057 - accuracy: 0.5781 - val_loss: 2.0834 - val_accuracy: 0.4343 - lr: 5.4881e-04\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 114s 91ms/step - loss: 1.4361 - accuracy: 0.5977 - val_loss: 2.0919 - val_accuracy: 0.4459 - lr: 4.9659e-04\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 122s 98ms/step - loss: 1.3730 - accuracy: 0.6194 - val_loss: 2.1057 - val_accuracy: 0.4367 - lr: 4.4933e-04\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 2.0631 - accuracy: 0.4417\n",
      "C3\n",
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 122s 93ms/step - loss: 3.0282 - accuracy: 0.2061 - val_loss: 2.6584 - val_accuracy: 0.2721 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 2.4587 - accuracy: 0.3284 - val_loss: 2.3651 - val_accuracy: 0.3483 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 117s 94ms/step - loss: 2.2014 - accuracy: 0.3950 - val_loss: 2.2428 - val_accuracy: 0.3746 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 132s 105ms/step - loss: 2.0258 - accuracy: 0.4444 - val_loss: 2.1868 - val_accuracy: 0.4036 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 150s 120ms/step - loss: 1.8941 - accuracy: 0.4878 - val_loss: 2.1483 - val_accuracy: 0.4204 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 132s 105ms/step - loss: 1.7847 - accuracy: 0.5253 - val_loss: 2.2525 - val_accuracy: 0.4078 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 127s 101ms/step - loss: 1.6762 - accuracy: 0.5620 - val_loss: 2.2988 - val_accuracy: 0.4206 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 124s 99ms/step - loss: 1.5838 - accuracy: 0.5958 - val_loss: 2.3038 - val_accuracy: 0.4259 - lr: 0.0010\n",
      "313/313 [==============================] - 10s 30ms/step - loss: 2.1483 - accuracy: 0.4204\n",
      "C4\n",
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 158s 119ms/step - loss: 2.9910 - accuracy: 0.0866 - val_loss: 2.7466 - val_accuracy: 0.1785 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 128s 102ms/step - loss: 2.7251 - accuracy: 0.1681 - val_loss: 2.5569 - val_accuracy: 0.2323 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 151s 121ms/step - loss: 2.5752 - accuracy: 0.2174 - val_loss: 2.4163 - val_accuracy: 0.2775 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 178s 143ms/step - loss: 2.4699 - accuracy: 0.2498 - val_loss: 2.3626 - val_accuracy: 0.2880 - lr: 0.0010\n",
      "Epoch 5/20\n",
      " 390/1250 [========>.....................] - ETA: 1:22 - loss: 2.3793 - accuracy: 0.2796"
     ]
    }
   ],
   "source": [
    "C1()\n",
    "model_name = 'C1'\n",
    "train_and_evaluate_model(sampler, model_name, retrain=True, perturbation=False)\n",
    "C2()\n",
    "model_name = 'C2'\n",
    "train_and_evaluate_model(sampler, model_name, retrain=True, perturbation=False)\n",
    "C3()\n",
    "model_name = 'C3'\n",
    "train_and_evaluate_model(sampler, model_name, retrain=True, perturbation=False)\n",
    "C4()\n",
    "model_name = 'C4'\n",
    "train_and_evaluate_model(sampler, model_name, retrain=True, perturbation=False)\n",
    "C5()\n",
    "model_name = 'C5'\n",
    "train_and_evaluate_model(sampler, model_name, retrain=True, perturbation=False)\n",
    "C6()\n",
    "model_name = 'C6'\n",
    "train_and_evaluate_model(sampler, model_name, retrain=True, perturbation=False)\n",
    "C7()\n",
    "model_name = 'C7'\n",
    "train_and_evaluate_model(sampler, model_name, retrain=True, perturbation=False)\n",
    "C8()\n",
    "model_name = 'C8'\n",
    "train_and_evaluate_model(sampler, model_name, retrain=True, perturbation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import visualkeras\n",
    "M5()\n",
    "model_name = 'M5'\n",
    "model = tf.keras.Model(input_img, y_pred)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "\n",
    "visualkeras.layered_view(model).save(f'architecture_images/{model_name}.png')\n",
    "# Plot the model architecture to a file (can be PNG, PDF, etc.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam-model-env",
   "language": "python",
   "name": "sam-model-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
